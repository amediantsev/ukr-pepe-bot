use lambda_http::{run, service_fn, Body, Error, Request, Response};
use async_openai::{
    types::{ChatCompletionRequestMessageArgs, CreateChatCompletionRequestArgs, Role},
    Client,
};
// use serde_json::{json};
use tbot::prelude::*;
use tbot::types::user::Id as UserChatId;


fn generate_main_user_message(messages: &[Message; 3]) -> String {
    let mut final_message = String::from(
        "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð´Ð¾Ð²Ð¶Ð¸Ð½Ð¾ÑŽ Ð²Ñ–Ð´ 5 Ð´Ð¾ 40 ÑÐ»Ñ–Ð² Ñƒ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÐµÐ½Ð½Ñ Ð´Ð¾ Ð±ÐµÑÑ–Ð´Ð¸ :\n"
    );
    for msg in messages.iter() {
        final_message += format!("{}:\n{}\n\n", msg.username, msg.text).as_str();
    }
    final_message
}

struct Message {
    username: String,
    text: String,
}

async fn function_handler(event: Request) -> Result<Response<Body>, Error> {
    let client = Client::new();

    // let messages = json!(
    //     [
    //         {
    //             "username": "Ð¡Ð°ÑˆÐºÐ¾",
    //             "text": "Ð„Ð±Ð°Ñ‚ÑŒ\nÐ—Ð½Ð°Ñ”Ñ‚Ðµ, ÑˆÐ¾ Ñ Ð·Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ð²?\n\
    //                     Ð¥Ð»Ð¾Ñ€Ð¾Ñ„Ñ–Ð» - Ñ†Ðµ...... Ð¢Ð¾Ð¹, Ñ…Ñ‚Ð¾ Ð»ÑŽÐ±Ð¸Ñ‚ÑŒ (Ð°Ð±Ð¾ Ð½Ð°Ð²Ñ–Ñ‚ÑŒ Ñ‚Ñ€Ð°Ñ…Ð°Ñ”) Ñ…Ð»Ð¾Ñ€ ðŸ˜³ðŸ˜³"
    //         },
    //         {
    //             "username": "Ð‘Ð¾Ñ€Ð¸Ñ",
    //             "text": "Ð¢Ñ–Ð»ÑŒÐºÐ¸ Ñ‚ÑƒÑ‚ Ñ…Ð»Ð¾Ñ€ Ð½Ðµ Ð² Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ– Ð³Ð°Ð·Ñƒ, Ð² Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ– \"Ð·ÐµÐ»ÐµÐ½Ð¸Ð¹\""},
    //         {
    //             "username": "Ð’Ð»Ð°Ð´",
    //             "text": "Ð¡Ð»Ð¾Ð½Ñ–Ðº"
    //         }
    //     ]
    // );
    let messages = [
        Message {
            username: "Ð¡Ð°ÑˆÐºÐ¾".to_string(),
            text: "Ð„Ð±Ð°Ñ‚ÑŒ\nÐ—Ð½Ð°Ñ”Ñ‚Ðµ, ÑˆÐ¾ Ñ Ð·Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ð²?\n\
                  Ð¥Ð»Ð¾Ñ€Ð¾Ñ„Ñ–Ð» - Ñ†Ðµ...... Ð¢Ð¾Ð¹, Ñ…Ñ‚Ð¾ Ð»ÑŽÐ±Ð¸Ñ‚ÑŒ (Ð°Ð±Ð¾ Ð½Ð°Ð²Ñ–Ñ‚ÑŒ Ñ‚Ñ€Ð°Ñ…Ð°Ñ”) Ñ…Ð»Ð¾Ñ€ ðŸ˜³ðŸ˜³".to_string()
        },
        Message {
            username: "Ð‘Ð¾Ñ€Ð¸Ñ".to_string(),
            text: "Ð¢Ñ–Ð»ÑŒÐºÐ¸ Ñ‚ÑƒÑ‚ Ñ…Ð»Ð¾Ñ€ Ð½Ðµ Ð² Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ– Ð³Ð°Ð·Ñƒ, Ð² Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ– \"Ð·ÐµÐ»ÐµÐ½Ð¸Ð¹\"".to_string()
        },
        Message {
            username: "Ð’Ð»Ð°Ð´".to_string(),
            text: "Ð¡Ð»Ð¾Ð½Ñ–Ðº".to_string()
        }
    ];

    // let request = CreateChatCompletionRequestArgs::default()
    //     .max_tokens(125_u16)
    //     .model("gpt-4")
    //     .temperature(0.7_f32)
    //     .messages([
    //         ChatCompletionRequestMessageArgs::default()
    //             .role(Role::System)
    //             .content(
    //                 "Act as a member of the friends group chat. \
    //                 You are a freaky, funny, and interesting companion. \
    //                 You like to says crazy things, \
    //                 which surprise and amuse your friends using swearing sometimes. \
    //                 You are rude a little."
    //                 // You love Ukraine, hate Russia and Putin. Sometimes you use ."
    //                 // #TODO finish
    //             )
    //             .build()?,
    //         ChatCompletionRequestMessageArgs::default()
    //             .role(Role::User)
    //             .content(generate_main_user_message(&messages))
    //             .build()?
    //     ])
    //     .build()?;
    //
    // let response = client.chat().create(request).await?;
    // let resp = Response::builder()
    //     .status(200)
    //     .body(response.choices[0].message.content.clone().into())
    //     .map_err(Box::new)?;
    let resp = Response::builder()
        .status(200)
        .body("OK".into())
        .map_err(Box::new)?;


    let mut bot = tbot::Bot::from_env("TELEGRAM_BOT_TOKEN");

    bot.send_message(UserChatId(355526766), "Hello world!").call().await.unwrap();
    // bot.polling().start().await.unwrap();
    Ok(resp)
}

#[tokio::main]
async fn main() -> Result<(), Error> {
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .with_target(false)
        .without_time()
        .init();

    run(service_fn(function_handler)).await
}
